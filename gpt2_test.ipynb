{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch import Tensor, nn\n",
    "from torch.nn.functional import normalize\n",
    "import transformer_lens\n",
    "from transformer_lens import HookedTransformer\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from sparse_QK_trainer import SparseQK, train_sparse_QK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformer_lens.HookedTransformer.from_pretrained(\"gpt2\", fold_ln = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "import datasets\n",
    "dataset = datasets.load_dataset(\"NeelNanda/pile-10k\", split=\"train\")\n",
    "print(dataset)\n",
    "print(dataset[0]['text'][:100])\n",
    "tokens_dataset = transformer_lens.utils.tokenize_and_concatenate(dataset, model.tokenizer, streaming=False, max_length=20, column_name=\"text\", add_bos_token=True, num_proc=4)\n",
    "data_loader = t.utils.data.DataLoader(tokens_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\"d_hidden\": 4096,\n",
    "       \"l1_coeff\": 1e-6,\n",
    "       \"d_model\": 768,\n",
    "       \"n_heads\": 1,\n",
    "       \"d_head\": 64,\n",
    "       \"seed\": 87,\n",
    "       \"device\": \"cuda:0\",\n",
    "       \"dead_freq\": 1e-7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_model = train_sparse_QK(model, cfg, 1, 10, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(12000, 2024)\n",
    "b = torch.rand(12000, 2024)\n",
    "\n",
    "a[:, 0] = 3.5\n",
    "a[:, -1] = 4\n",
    "a[:, 200] = 3.5\n",
    "a[:, 40] = 4\n",
    "\n",
    "b[:, 0] = 3\n",
    "b[:, 200] = 6\n",
    "b[:, -1] = 3\n",
    "b[:, 40] = 4\n",
    "\n",
    "a = a.log_softmax(-1)\n",
    "b = b.log_softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.8162, -8.1875, -8.7133,  ..., -8.7480, -7.8456, -1.8162])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl = torch.nn.KLDivLoss(reduction = 'batchmean', log_target = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2334)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4049e-01, 1.4139e-05, 1.2405e-05,  ..., 2.0183e-05, 1.1473e-05,\n",
       "         2.4049e-01],\n",
       "        [2.4041e-01, 2.6309e-05, 2.5727e-05,  ..., 1.3227e-05, 2.6517e-05,\n",
       "         2.4041e-01],\n",
       "        [2.4051e-01, 1.1379e-05, 1.6808e-05,  ..., 1.6009e-05, 1.4333e-05,\n",
       "         2.4051e-01],\n",
       "        ...,\n",
       "        [2.4053e-01, 1.1605e-05, 1.4606e-05,  ..., 1.4004e-05, 2.8144e-05,\n",
       "         2.4053e-01],\n",
       "        [2.4060e-01, 1.5101e-05, 1.5010e-05,  ..., 2.7902e-05, 1.4501e-05,\n",
       "         2.4060e-01],\n",
       "        [2.4053e-01, 1.3397e-05, 1.6657e-05,  ..., 1.2777e-05, 1.9051e-05,\n",
       "         2.4053e-01]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
